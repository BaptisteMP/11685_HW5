{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SRGAN Submission code",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Environment (conda_pytorch_p36)",
      "language": "python",
      "name": "conda_pytorch_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rwIS_cFvmYL",
        "outputId": "548366f1-ef87-4965-baf3-ec7bd4d0d7b8"
      },
      "source": [
        "print((\"Let's get this money!!\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's get this money!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J70aH3_7M94o"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#!cp /content/gdrive/MyDrive/HW5_train_val.zip /content\n",
        "#!unzip HW5_train_val.zip\n",
        "#!cp /content/gdrive/MyDrive/HW5_test.zip /content\n",
        "!mkdir /content/test/\n",
        "\n",
        "!mv HW5_test.zip /content/test/  \n",
        "\n",
        "!unzip /content/test/HW5_test.zip -d /content/test/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3sBonHGHvQ1"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision   \n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "cuda = torch.device('cuda')\n",
        "cpu = torch.device('cpu')\n",
        "device = cuda\n",
        "\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGKOK00eF6gR"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        upsample_block_num = 2\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(64)\n",
        "        self.block3 = ResidualBlock(64)\n",
        "        self.block4 = ResidualBlock(64)\n",
        "        self.block5 = ResidualBlock(64)\n",
        "        self.block6 = ResidualBlock(64)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        block8 = [UpsampleBLock(64, 2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(1024, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return torch.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x\n",
        "\n",
        "#generator = Generator()\n",
        "generator = torch.load(\"/content/gdrive/MyDrive/gen_v3.pth\")\n",
        "#discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9RSBzzSiwQE"
      },
      "source": [
        "transform_train = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "\n",
        "# datasets = torchvision.datasets.ImageFolder(root='/home/ubuntu/content/DIV2K_valid_LR_bicubic')\n",
        "# train_dataset_LR = torchvision.datasets.ImageFolder(root='/content/train_LR/', \n",
        "#                                                   transform=transform_train)\n",
        "# dev_dataset_HR = torchvision.datasets.ImageFolder(root='/content/DIV2K_valid_HR/')\n",
        "# train_dataset_HR = torchvision.datasets.ImageFolder(root='/content/train_HR/', \n",
        "#                                                    transform=transform_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AQOKWUIpZo"
      },
      "source": [
        "transform_train = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225],\n",
        "    ),\n",
        "])\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='/content/test/', \n",
        "                                                   transform=transform_train)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dvBKVsDjJj3C",
        "outputId": "e5ed1adb-d9f3-4a76-8298-f81339fa63a6"
      },
      "source": [
        "'/'.join(['submission']+test_dataset.imgs[0][0].split('/')[-2:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'submission/comics/ARMS.png'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6XWSCkKK8RY"
      },
      "source": [
        "transforms.ToPILImage()(generator(next(iter(test_dataset))[0].unsqueeze(0).cuda())[0]).save('/'.join(['submission']+test_dataset.imgs[0][0].split('/')[-2:]),format=\"png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJDDqaOtJMRW"
      },
      "source": [
        "!mkdir /content/submission/\n",
        "!mkdir /content/submission/comics/\n",
        "!mkdir /content/submission/large_test\n",
        "!mkdir /content/submission/small_test/\n",
        "!mkdir /content/submission/structures/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0h4--LPO7Da"
      },
      "source": [
        "for i, (img,_) in enumerate(test_dataset):\n",
        "  filename = test_dataset.imgs[i][0]\n",
        "  sr = generator(img.unsqueeze(0).cuda())[0]\n",
        "  sr = transforms.ToPILImage()(sr)\n",
        "  sr.save('/'.join(['submission']+filename.split('/')[-2:]), format=\"png\")\n",
        "  print(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK6NXqltSXBz"
      },
      "source": [
        "!zip -r submission.zip submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-WQEAWKTFON"
      },
      "source": [
        "!cp submission.zip /content/gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}